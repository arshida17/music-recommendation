{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.optimizers import Adam\nimport tensorflow as tf\n\ntrain_dir = '/kaggle/input/fer2013/train'\nval_dir = '/kaggle/input/fer2013/test'\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\nval_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size = (48,48),\n    batch_size = 64,\n    color_mode = \"grayscale\",\n    class_mode = 'categorical'\n)\n\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size = (48,48),\n    batch_size = 64,\n    color_mode = \"grayscale\",\n    class_mode = 'categorical'\n)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-17T05:18:15.100901Z","iopub.execute_input":"2024-04-17T05:18:15.101293Z","iopub.status.idle":"2024-04-17T05:18:31.167135Z","shell.execute_reply.started":"2024-04-17T05:18:15.101242Z","shell.execute_reply":"2024-04-17T05:18:31.166302Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 28709 images belonging to 7 classes.\nFound 7178 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"emotion_model = Sequential()\n\nemotion_model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape = (48,48,1)))\nemotion_model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2,2)))\nemotion_model.add(Dropout(0.25))\n\nemotion_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2,2)))\nemotion_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2,2)))\nemotion_model.add(Dropout(0.25))\n\nemotion_model.add(Flatten())\nemotion_model.add(Dense(1024, activation='relu'))\nemotion_model.add(Dropout(0.5))\nemotion_model.add(Dense(7, activation='softmax'))\n\nemotion_model.compile(loss='categorical_crossentropy',optimizer=Adam(decay=1e-6),metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T05:19:10.403452Z","iopub.execute_input":"2024-04-17T05:19:10.403832Z","iopub.status.idle":"2024-04-17T05:19:10.544184Z","shell.execute_reply.started":"2024-04-17T05:19:10.403804Z","shell.execute_reply":"2024-04-17T05:19:10.543297Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"emotion_model_info = emotion_model.fit(\n    train_generator,\n    steps_per_epoch = 28709 // 64,\n    epochs=75,\n    validation_data = val_generator,\n    validation_steps = 7178 // 64\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T05:20:17.868719Z","iopub.execute_input":"2024-04-17T05:20:17.869101Z","iopub.status.idle":"2024-04-17T05:45:07.332973Z","shell.execute_reply.started":"2024-04-17T05:20:17.869072Z","shell.execute_reply":"2024-04-17T05:45:07.331820Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/75\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:27\u001b[0m 13s/step - accuracy: 0.1406 - loss: 1.9558","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1713331231.165424     101 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1713331231.183877     101 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.2713 - loss: 1.7847","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1713331351.746302     100 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 328ms/step - accuracy: 0.2714 - loss: 1.7845 - val_accuracy: 0.4198 - val_loss: 1.4935\nEpoch 2/75\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.5156 - loss: 1.4392","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5156 - loss: 1.4392 - val_accuracy: 0.4000 - val_loss: 1.5510\nEpoch 3/75\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1713331379.002187     103 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.4251 - loss: 1.4881 - val_accuracy: 0.4969 - val_loss: 1.3296\nEpoch 4/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.4531 - loss: 1.4437 - val_accuracy: 0.4000 - val_loss: 1.7820\nEpoch 5/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.4966 - loss: 1.3140 - val_accuracy: 0.5289 - val_loss: 1.2144\nEpoch 6/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32us/step - accuracy: 0.4844 - loss: 1.5878 - val_accuracy: 0.7000 - val_loss: 1.1447\nEpoch 7/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.5293 - loss: 1.2364 - val_accuracy: 0.5419 - val_loss: 1.2000\nEpoch 8/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32us/step - accuracy: 0.4844 - loss: 1.2427 - val_accuracy: 0.4000 - val_loss: 1.4688\nEpoch 9/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.5557 - loss: 1.1632 - val_accuracy: 0.5688 - val_loss: 1.1505\nEpoch 10/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36us/step - accuracy: 0.5938 - loss: 1.2589 - val_accuracy: 0.5000 - val_loss: 1.4259\nEpoch 11/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 79ms/step - accuracy: 0.5823 - loss: 1.1093 - val_accuracy: 0.5776 - val_loss: 1.1194\nEpoch 12/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30us/step - accuracy: 0.5938 - loss: 1.1267 - val_accuracy: 0.6000 - val_loss: 0.8119\nEpoch 13/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.5935 - loss: 1.0700 - val_accuracy: 0.5718 - val_loss: 1.1313\nEpoch 14/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.4844 - loss: 1.3123 - val_accuracy: 0.6000 - val_loss: 0.7391\nEpoch 15/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 84ms/step - accuracy: 0.6150 - loss: 1.0266 - val_accuracy: 0.5880 - val_loss: 1.0827\nEpoch 16/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32us/step - accuracy: 0.6250 - loss: 1.1269 - val_accuracy: 0.6000 - val_loss: 0.9657\nEpoch 17/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 75ms/step - accuracy: 0.6279 - loss: 0.9938 - val_accuracy: 0.5977 - val_loss: 1.0698\nEpoch 18/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.6875 - loss: 1.0422 - val_accuracy: 0.5000 - val_loss: 1.4935\nEpoch 19/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 75ms/step - accuracy: 0.6440 - loss: 0.9579 - val_accuracy: 0.6062 - val_loss: 1.0674\nEpoch 20/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.5156 - loss: 1.1663 - val_accuracy: 0.4000 - val_loss: 1.3887\nEpoch 21/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.6539 - loss: 0.9215 - val_accuracy: 0.6110 - val_loss: 1.0529\nEpoch 22/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.6875 - loss: 0.9246 - val_accuracy: 0.5000 - val_loss: 1.1664\nEpoch 23/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 75ms/step - accuracy: 0.6722 - loss: 0.8867 - val_accuracy: 0.6077 - val_loss: 1.0662\nEpoch 24/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.4688 - loss: 1.1998 - val_accuracy: 0.7000 - val_loss: 0.9175\nEpoch 25/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 79ms/step - accuracy: 0.6790 - loss: 0.8491 - val_accuracy: 0.6136 - val_loss: 1.0604\nEpoch 26/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.7188 - loss: 0.7596 - val_accuracy: 0.8000 - val_loss: 0.7468\nEpoch 27/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 74ms/step - accuracy: 0.6902 - loss: 0.8257 - val_accuracy: 0.6184 - val_loss: 1.0507\nEpoch 28/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30us/step - accuracy: 0.7031 - loss: 0.7589 - val_accuracy: 0.6000 - val_loss: 0.9858\nEpoch 29/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 78ms/step - accuracy: 0.7011 - loss: 0.7980 - val_accuracy: 0.6240 - val_loss: 1.0611\nEpoch 30/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32us/step - accuracy: 0.7188 - loss: 0.7281 - val_accuracy: 0.8000 - val_loss: 1.0718\nEpoch 31/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.7175 - loss: 0.7554 - val_accuracy: 0.6172 - val_loss: 1.0599\nEpoch 32/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29us/step - accuracy: 0.6875 - loss: 0.7925 - val_accuracy: 0.7000 - val_loss: 0.9974\nEpoch 33/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.7305 - loss: 0.7254 - val_accuracy: 0.6247 - val_loss: 1.0694\nEpoch 34/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.6875 - loss: 0.7736 - val_accuracy: 0.6000 - val_loss: 1.1300\nEpoch 35/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.7399 - loss: 0.7016 - val_accuracy: 0.6239 - val_loss: 1.0884\nEpoch 36/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.7656 - loss: 0.6024 - val_accuracy: 0.7000 - val_loss: 0.5488\nEpoch 37/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.7433 - loss: 0.6847 - val_accuracy: 0.6226 - val_loss: 1.0827\nEpoch 38/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29us/step - accuracy: 0.6875 - loss: 0.7689 - val_accuracy: 0.7000 - val_loss: 0.7614\nEpoch 39/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.7555 - loss: 0.6665 - val_accuracy: 0.6194 - val_loss: 1.1022\nEpoch 40/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.7500 - loss: 0.6145 - val_accuracy: 0.7000 - val_loss: 1.4568\nEpoch 41/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 75ms/step - accuracy: 0.7626 - loss: 0.6435 - val_accuracy: 0.6212 - val_loss: 1.1216\nEpoch 42/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30us/step - accuracy: 0.7812 - loss: 0.7313 - val_accuracy: 0.9000 - val_loss: 0.4204\nEpoch 43/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 75ms/step - accuracy: 0.7644 - loss: 0.6332 - val_accuracy: 0.6243 - val_loss: 1.0913\nEpoch 44/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.7031 - loss: 0.7445 - val_accuracy: 0.8000 - val_loss: 0.3595\nEpoch 45/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 76ms/step - accuracy: 0.7744 - loss: 0.6123 - val_accuracy: 0.6246 - val_loss: 1.1083\nEpoch 46/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.7344 - loss: 0.6606 - val_accuracy: 0.5000 - val_loss: 1.0012\nEpoch 47/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.7889 - loss: 0.5770 - val_accuracy: 0.6235 - val_loss: 1.1070\nEpoch 48/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.7500 - loss: 0.5577 - val_accuracy: 0.5000 - val_loss: 2.0525\nEpoch 49/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 86ms/step - accuracy: 0.7883 - loss: 0.5690 - val_accuracy: 0.6217 - val_loss: 1.1115\nEpoch 50/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.7656 - loss: 0.7043 - val_accuracy: 0.8000 - val_loss: 0.7010\nEpoch 51/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 83ms/step - accuracy: 0.7934 - loss: 0.5682 - val_accuracy: 0.6191 - val_loss: 1.1216\nEpoch 52/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.8125 - loss: 0.6279 - val_accuracy: 0.4000 - val_loss: 1.8849\nEpoch 53/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 95ms/step - accuracy: 0.8035 - loss: 0.5376 - val_accuracy: 0.6283 - val_loss: 1.1587\nEpoch 54/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32us/step - accuracy: 0.6094 - loss: 0.9359 - val_accuracy: 0.4000 - val_loss: 1.3131\nEpoch 55/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 96ms/step - accuracy: 0.8022 - loss: 0.5364 - val_accuracy: 0.6194 - val_loss: 1.1357\nEpoch 56/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30us/step - accuracy: 0.7969 - loss: 0.5938 - val_accuracy: 0.6000 - val_loss: 1.3965\nEpoch 57/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 91ms/step - accuracy: 0.8078 - loss: 0.5275 - val_accuracy: 0.6230 - val_loss: 1.1479\nEpoch 58/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.7188 - loss: 0.6174 - val_accuracy: 0.5000 - val_loss: 0.8876\nEpoch 59/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 79ms/step - accuracy: 0.8097 - loss: 0.5133 - val_accuracy: 0.6246 - val_loss: 1.1696\nEpoch 60/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.7500 - loss: 0.6888 - val_accuracy: 0.5000 - val_loss: 0.9295\nEpoch 61/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.8120 - loss: 0.5134 - val_accuracy: 0.6316 - val_loss: 1.1717\nEpoch 62/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32us/step - accuracy: 0.8906 - loss: 0.3280 - val_accuracy: 0.4000 - val_loss: 2.2913\nEpoch 63/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.8127 - loss: 0.5089 - val_accuracy: 0.6316 - val_loss: 1.1675\nEpoch 64/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.7656 - loss: 0.6497 - val_accuracy: 0.5000 - val_loss: 1.8473\nEpoch 65/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.8195 - loss: 0.4933 - val_accuracy: 0.6254 - val_loss: 1.1589\nEpoch 66/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.7500 - loss: 0.6699 - val_accuracy: 0.7000 - val_loss: 1.5798\nEpoch 67/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.8257 - loss: 0.4827 - val_accuracy: 0.6230 - val_loss: 1.1943\nEpoch 68/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32us/step - accuracy: 0.7969 - loss: 0.5825 - val_accuracy: 0.7000 - val_loss: 0.5375\nEpoch 69/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.8309 - loss: 0.4736 - val_accuracy: 0.6177 - val_loss: 1.2005\nEpoch 70/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32us/step - accuracy: 0.8594 - loss: 0.4021 - val_accuracy: 0.6000 - val_loss: 1.2105\nEpoch 71/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 75ms/step - accuracy: 0.8308 - loss: 0.4702 - val_accuracy: 0.6250 - val_loss: 1.1902\nEpoch 72/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.7812 - loss: 0.5433 - val_accuracy: 0.9000 - val_loss: 0.3985\nEpoch 73/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.8366 - loss: 0.4570 - val_accuracy: 0.6264 - val_loss: 1.1952\nEpoch 74/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.7969 - loss: 0.6573 - val_accuracy: 0.7000 - val_loss: 0.9348\nEpoch 75/75\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.8420 - loss: 0.4406 - val_accuracy: 0.6225 - val_loss: 1.2047\n","output_type":"stream"}]},{"cell_type":"code","source":"emotion_model.save('model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:23:35.754246Z","iopub.execute_input":"2024-04-17T06:23:35.754613Z","iopub.status.idle":"2024-04-17T06:23:35.855722Z","shell.execute_reply.started":"2024-04-17T06:23:35.754587Z","shell.execute_reply":"2024-04-17T06:23:35.854810Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}